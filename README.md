# Perceptron Implementation

This project demonstrates the implementation of a **Perceptron**, used for binary classification tasks.

## ğŸ“˜ Description

The notebook walks through a step-by-step implementation of the perceptron algorithm, including:

- Initialization of weights and bias
- Activation function
- Training process using labeled data
- Prediction on new data
- Visualization of the decision boundary

The goal is to showcase how a perceptron learns to classify linearly separable data.

## ğŸš€ Features

- Manual implementation without using deep learning libraries
- Visual representation of the classification process
- Easy-to-understand code

## ğŸ§  Algorithm

The perceptron follows these steps:

1. Initialize weights and bias
2. For each training sample:
   - Compute the weighted sum
   - Apply the activation function
   - Update the weights based on the error
3. Repeat for a number of epochs or until convergence

## ğŸ“¦ Requirements

To run this project, you need:

- Python 3.x
- Jupyter Notebook
- `matplotlib`
- `numpy`
- `scikit-learn`

You can install the dependencies using:

```bash
pip install matplotlib numpy sklearn
```

## ğŸ“ Usage

- Clone the repository or download the notebook.
- Open `Perceptron.ipynb` in Jupyter Notebook or JupyterLab.
- Run the cells sequentially to see the perceptron in action.

## ğŸ“Š Example Output

The notebook includes plots showing how the decision boundary evolves as the perceptron learns.

## ğŸ“ License

This project is open-source and available under the [MIT License](https://opensource.org/licenses/MIT).

---
Feel free to contribute or modify the code to explore more advanced neural network concepts!
